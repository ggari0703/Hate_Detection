{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDNurOmsLkEV","executionInfo":{"status":"ok","timestamp":1716468247765,"user_tz":-540,"elapsed":1160,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"c382dcd0-c64a-469b-826a-6d7e52da32b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                            comments  contain_gender_bias  \\\n","0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...                    0   \n","1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...                    0   \n","2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...                    0   \n","3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데                    0   \n","4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...                    1   \n","\n","   bias  hate  \n","0     1     1  \n","1     0     0  \n","2     0     1  \n","3     0     0  \n","4     1     1  \n","Shape of X: (7896, 100)\n","Shape of y: (7896, 3)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import re\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Load the dataset\n","file_path = '/content/drive/MyDrive/DLproject/dataset/KHS_dataset.txt'\n","data = pd.read_csv(file_path, delimiter=',')\n","\n","# Display the first few rows of the dataset\n","print(data.head())\n","\n","# Define the labels\n","labels = ['contain_gender' , 'bias' , 'hate']\n","# Text cleaning function\n","def clean_text(text):\n","    # Remove non-alphanumeric characters and extra spaces\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = re.sub(r\"[^a-zA-Z가-힣0-9\\s]\", \"\", text)\n","    return text.strip()\n","\n","# Clean the 'comments' column\n","data['comments'] = data['comments'].apply(clean_text)\n","\n","# Convert labels to a list of labels\n","def extract_labels(row):\n","    return [labels[i] for i in range(len(labels)) if row[i+1] == 1]\n","\n","data['labels'] = data.apply(extract_labels, axis=1)\n","\n","# Tokenize the sentences\n","max_words = 10000 #수정\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(data['comments'])\n","sequences = tokenizer.texts_to_sequences(data['comments'])\n","\n","# Pad the sequences\n","maxlen = 100  # You can adjust the maxlen according to your needs\n","X = pad_sequences(sequences, maxlen=maxlen)\n","\n","# Binarize the labels\n","mlb = MultiLabelBinarizer(classes=labels)\n","y = mlb.fit_transform(data['labels'])\n","\n","# Print the shape of the dataset\n","print(f'Shape of X: {X.shape}')\n","print(f'Shape of y: {y.shape}')\n","\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBmUGTm8NqpT","executionInfo":{"status":"ok","timestamp":1716466018198,"user_tz":-540,"elapsed":19008,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"3e3f785c-c787-4349-a85a-b3a94fe7a797"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CsGDp6E-LkEg","executionInfo":{"status":"ok","timestamp":1716468249741,"user_tz":-540,"elapsed":365,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"ea500f97-3104-41fc-e72c-dd8ca0012ad5"},"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합(vocabulary)의 크기 : 37086\n","등장 빈도가 2번 이하인 희귀 단어의 수: 33817\n","단어 집합에서 희귀 단어의 비율: 91.1853529633824\n","전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 57.118334776691825\n"]}],"source":["threshold = 3\n","total_cnt = len(tokenizer.word_index) # 단어의 수\n","rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n","rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n","\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n","for key, value in tokenizer.word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('단어 집합(vocabulary)의 크기 :',total_cnt)\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pKf5emoLkEh","executionInfo":{"status":"ok","timestamp":1716468216994,"user_tz":-540,"elapsed":2,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"4d51afaa-2564-4dfa-84d2-c23ae5fa3ef2"},"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합의 크기 : 31709\n"]}],"source":["# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n","# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n","vocab_size = total_cnt - rare_cnt + 2\n","print('단어 집합의 크기 :',vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DURvR_43LkEi","executionInfo":{"status":"ok","timestamp":1716468251825,"user_tz":-540,"elapsed":326,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"3c38ed99-3590-4fe6-b613-a79dade33ecc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X_train: (6316, 100)\n","Shape of y_train: (6316, 3)\n","Shape of X_test: (1580, 100)\n","Shape of y_test: (1580, 3)\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 100, 128)          1280000   \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 96, 128)           82048     \n","                                                                 \n"," global_max_pooling1d_1 (Gl  (None, 128)               0         \n"," obalMaxPooling1D)                                               \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 1378947 (5.26 MB)\n","Trainable params: 1378947 (5.26 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f'Shape of X_train: {X_train.shape}')\n","print(f'Shape of y_train: {y_train.shape}')\n","print(f'Shape of X_test: {X_test.shape}')\n","print(f'Shape of y_test: {y_test.shape}')\n","\n","model_01 = Sequential()\n","model_01.add(Embedding(max_words, 128, input_length=maxlen))\n","model_01.add(Conv1D(128, 5, activation='relu'))\n","model_01.add(GlobalMaxPooling1D())\n","model_01.add(Dense(128, activation='relu'))\n","model_01.add(Dropout(0.5))\n","model_01.add(Dense(len(labels), activation='sigmoid'))\n","\n","model_01.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","model_01.summary()"]},{"cell_type":"code","source":["model_01.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","\n","# Train the model\n","history = model_01.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5CYp0R7Pe_V","executionInfo":{"status":"ok","timestamp":1716468379333,"user_tz":-540,"elapsed":125357,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"6aa5c398-b50c-481a-dd8a-0031ea80735a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","158/158 [==============================] - 16s 96ms/step - loss: 0.5955 - accuracy: 0.2379 - val_loss: 0.5809 - val_accuracy: 0.2381\n","Epoch 2/10\n","158/158 [==============================] - 16s 103ms/step - loss: 0.5128 - accuracy: 0.2367 - val_loss: 0.5416 - val_accuracy: 0.2381\n","Epoch 3/10\n","158/158 [==============================] - 12s 78ms/step - loss: 0.3419 - accuracy: 0.2385 - val_loss: 0.6178 - val_accuracy: 0.2373\n","Epoch 4/10\n","158/158 [==============================] - 13s 85ms/step - loss: 0.2187 - accuracy: 0.2486 - val_loss: 0.7647 - val_accuracy: 0.2334\n","Epoch 5/10\n","158/158 [==============================] - 9s 59ms/step - loss: 0.1487 - accuracy: 0.2603 - val_loss: 0.9062 - val_accuracy: 0.2445\n","Epoch 6/10\n","158/158 [==============================] - 12s 74ms/step - loss: 0.1113 - accuracy: 0.2643 - val_loss: 1.0669 - val_accuracy: 0.2437\n","Epoch 7/10\n","158/158 [==============================] - 12s 74ms/step - loss: 0.0892 - accuracy: 0.2621 - val_loss: 1.1942 - val_accuracy: 0.2484\n","Epoch 8/10\n","158/158 [==============================] - 10s 63ms/step - loss: 0.0756 - accuracy: 0.2625 - val_loss: 1.3017 - val_accuracy: 0.2453\n","Epoch 9/10\n","158/158 [==============================] - 11s 71ms/step - loss: 0.0705 - accuracy: 0.2672 - val_loss: 1.4687 - val_accuracy: 0.2492\n","Epoch 10/10\n","158/158 [==============================] - 13s 80ms/step - loss: 0.0665 - accuracy: 0.2710 - val_loss: 1.5374 - val_accuracy: 0.2460\n"]}]},{"cell_type":"code","source":["y_sample = pd.DataFrame(y[:50], columns=labels)\n","print(y_sample)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"wpegXWRYWGvE","executionInfo":{"status":"ok","timestamp":1716467189057,"user_tz":-540,"elapsed":330,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"d0e24881-64eb-47d5-e482-db3cebb0ca7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["    contain_gender  bias  hate\n","0                0     1     1\n","1                0     0     0\n","2                0     0     1\n","3                0     0     0\n","4                1     1     1\n","5                0     0     0\n","6                1     1     1\n","7                0     0     0\n","8                0     0     1\n","9                0     0     1\n","10               0     1     0\n","11               0     0     0\n","12               0     0     0\n","13               0     0     1\n","14               0     0     0\n","15               0     1     1\n","16               0     0     0\n","17               0     1     0\n","18               0     0     0\n","19               1     1     1\n","20               0     0     1\n","21               0     0     0\n","22               0     0     0\n","23               0     0     1\n","24               0     0     0\n","25               0     0     0\n","26               0     0     1\n","27               0     0     0\n","28               0     0     0\n","29               0     0     0\n","30               0     0     0\n","31               0     0     0\n","32               0     0     0\n","33               1     1     1\n","34               0     0     0\n","35               0     1     1\n","36               0     1     1\n","37               0     0     1\n","38               0     0     0\n","39               0     0     0\n","40               0     0     0\n","41               0     0     0\n","42               0     0     0\n","43               0     0     1\n","44               0     1     0\n","45               1     1     1\n","46               0     1     1\n","47               0     1     1\n","48               0     0     0\n","49               0     1     1\n"]}]},{"cell_type":"markdown","source":["데이터 불균형 여부를 확인"],"metadata":{"id":"VudVbYkMW-Wz"}},{"cell_type":"code","source":["# 데이터 불균형 문제 파악\n","y_df = pd.DataFrame(y, columns=labels)\n","\n","# Calculate the distribution of each combination\n","combination_distribution = y_df.groupby(labels).size().reset_index(name='count')\n","\n","# Print the distribution\n","print(combination_distribution)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J66xrL0VWpHD","executionInfo":{"status":"ok","timestamp":1716467193257,"user_tz":-540,"elapsed":353,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"f2824857-476a-4181-bea9-1a0b608d8465"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   contain_gender  bias  hate  count\n","0               0     0     0   3273\n","1               0     0     1   1875\n","2               0     1     0    137\n","3               0     1     1   1379\n","4               1     1     0     76\n","5               1     1     1   1156\n"]}]},{"cell_type":"code","source":["from nltk.corpus import wordnet\n","import random\n","import nltk\n","from nltk.corpus import stopwords\n","\n","# NLTK의 stopwords 로드\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# 원본 데이터프레임에 각 라벨을 개별 컬럼으로 분리\n","for label in labels:\n","    data[label] = data['labels'].apply(lambda x: 1 if label in x else 0)\n","\n","# 부족한 클래스 조합 확인\n","combination_distribution = data.groupby(labels).size().reset_index(name='count')\n","print(\"Class combination distribution before augmentation:\")\n","print(combination_distribution)\n","\n","# 증강할 클래스 조합 기준 설정 (예: 기준보다 적은 샘플을 가진 조합들에 대해 증강)\n","augmentation_threshold = 1000  # 적절한 기준값 설정\n","combinations_to_augment = combination_distribution[combination_distribution['count'] < augmentation_threshold]\n","\n","# 증강 기법 정의\n","def synonym_replacement(sentence, n):\n","    words = sentence.split()\n","    new_words = words.copy()\n","    random_word_list = list(set([word for word in words if word not in stopwords.words('english')]))\n","    random.shuffle(random_word_list)\n","    num_replaced = 0\n","    for random_word in random_word_list:\n","        synonyms = get_synonyms(random_word)\n","        if len(synonyms) >= 1:\n","            synonym = random.choice(list(synonyms))\n","            new_words = [synonym if word == random_word else word for word in new_words]\n","            num_replaced += 1\n","        if num_replaced >= n:  # n개의 단어를 치환하면 종료\n","            break\n","    return ' '.join(new_words)\n","\n","def get_synonyms(word):\n","    synonyms = set()\n","    for syn in wordnet.synsets(word):\n","        for lemma in syn.lemmas():\n","            synonyms.add(lemma.name())\n","    if word in synonyms:\n","        synonyms.remove(word)\n","    return synonyms\n","\n","def random_insertion(sentence, n):\n","    words = sentence.split()\n","    for _ in range(n):\n","        new_word = random.choice(words)\n","        synonyms = get_synonyms(new_word)\n","        if len(synonyms) >= 1:\n","            synonym = random.choice(list(synonyms))\n","            insert_pos = random.randint(0, len(words)-1)\n","            words.insert(insert_pos, synonym)\n","    return ' '.join(words)\n","\n","def random_deletion(sentence, p):\n","    words = sentence.split()\n","    if len(words) == 1:\n","        return sentence\n","    new_words = []\n","    for word in words:\n","        r = random.uniform(0, 1)\n","        if r > p:\n","            new_words.append(word)\n","    if len(new_words) == 0:\n","        return random.choice(words)\n","    return ' '.join(new_words)\n","\n","def random_swap(sentence, n):\n","    words = sentence.split()\n","    length = len(words)\n","    for _ in range(n):\n","        idx1, idx2 = random.sample(range(length), 2)\n","        words[idx1], words[idx2] = words[idx2], words[idx1]\n","    return ' '.join(words)\n","\n","# 데이터 증강 함수 (다양한 기법 사용)\n","def augment_data(row, n_synonym_replacements=2, n_random_insertions=2, n_random_deletions=2, n_random_swaps=2):\n","    augmented_sentences = []\n","\n","    # 동의어 치환\n","    augmented_sentences.append(synonym_replacement(row['comments'], n_synonym_replacements))\n","\n","    # 무작위 삽입\n","    augmented_sentences.append(random_insertion(row['comments'], n_random_insertions))\n","\n","    # 무작위 삭제\n","    augmented_sentences.append(random_deletion(row['comments'], 0.2))  # 20% 확률로 단어 삭제\n","\n","    # 무작위 교체\n","    augmented_sentences.append(random_swap(row['comments'], n_random_swaps))\n","\n","    augmented_data = [{'comments': sentence, 'contain_gender': row['contain_gender'], 'bias': row['bias'], 'hate': row['hate']} for sentence in augmented_sentences]\n","    return augmented_data\n","\n","# 부족한 클래스 조합의 데이터만 증강\n","augmented_data = []\n","\n","for index, row in combinations_to_augment.iterrows():\n","    condition = (data['contain_gender'] == row['contain_gender']) & (data['bias'] == row['bias']) & (data['hate'] == row['hate'])\n","    class_data = data[condition]\n","    for idx, class_row in class_data.iterrows():\n","        augmented_data.extend(augment_data(class_row))  # 각 방법으로 증강\n","\n","# 증강된 데이터프레임 생성\n","augmented_df = pd.DataFrame(augmented_data)\n","\n","# 원본 데이터와 증강된 데이터 합치기\n","final_data = pd.concat([data, augmented_df])\n","\n","# Tokenize and pad sequences again with the new augmented data\n","tokenizer.fit_on_texts(final_data['comments'])\n","sequences = tokenizer.texts_to_sequences(final_data['comments'])\n","X_augmented = pad_sequences(sequences, maxlen=maxlen)\n","\n","# Update labels\n","y_augmented = final_data[['contain_gender', 'bias', 'hate']].values\n","\n","print(f'Shape of augmented X: {X_augmented.shape}')\n","print(f'Shape of augmented y: {y_augmented.shape}')\n","\n","# 증강 후 클래스 분포 확인\n","y_df_augmented = pd.DataFrame(y_augmented, columns=labels)\n","combination_distribution_augmented = y_df_augmented.groupby(labels).size().reset_index(name='count')\n","print(\"Class combination distribution after augmentation:\")\n","print(combination_distribution_augmented)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELlPjCehf1-7","executionInfo":{"status":"ok","timestamp":1716469270183,"user_tz":-540,"elapsed":2407,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"b76a5d4b-2f73-45ae-c2e7-8159fc5db24b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Class combination distribution before augmentation:\n","   contain_gender  bias  hate  count\n","0               0     0     0   3273\n","1               0     0     1   1875\n","2               0     1     0    137\n","3               0     1     1   1379\n","4               1     1     0     76\n","5               1     1     1   1156\n","Shape of augmented X: (8748, 100)\n","Shape of augmented y: (8748, 3)\n","Class combination distribution after augmentation:\n","   contain_gender  bias  hate  count\n","0               0     0     0   3273\n","1               0     0     1   1875\n","2               0     1     0    685\n","3               0     1     1   1379\n","4               1     1     0    380\n","5               1     1     1   1156\n"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)\n","\n","print(f'Shape of X_train: {X_train.shape}')\n","print(f'Shape of y_train: {y_train.shape}')\n","print(f'Shape of X_test: {X_test.shape}')\n","print(f'Shape of y_test: {y_test.shape}')\n","\n","model_02 = Sequential()\n","model_02.add(Embedding(max_words, 128, input_length=maxlen))\n","model_02.add(Conv1D(128, 5, activation='relu'))\n","model_02.add(GlobalMaxPooling1D())\n","model_02.add(Dense(128, activation='relu'))\n","model_02.add(Dropout(0.5))\n","model_02.add(Dense(len(labels), activation='sigmoid'))\n","\n","model_02.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","model_02.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EaUSVaGuiwcG","executionInfo":{"status":"ok","timestamp":1716469350141,"user_tz":-540,"elapsed":15,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"dbb35107-dc96-4a9e-d8f2-d0078486ec91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X_train: (6998, 100)\n","Shape of y_train: (6998, 3)\n","Shape of X_test: (1750, 100)\n","Shape of y_test: (1750, 3)\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 100, 128)          1280000   \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 96, 128)           82048     \n","                                                                 \n"," global_max_pooling1d_2 (Gl  (None, 128)               0         \n"," obalMaxPooling1D)                                               \n","                                                                 \n"," dense_4 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 1378947 (5.26 MB)\n","Trainable params: 1378947 (5.26 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_02.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","\n","# Train the model\n","history = model_02.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQHDmbkajDVn","executionInfo":{"status":"ok","timestamp":1716469535190,"user_tz":-540,"elapsed":145439,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"7de79032-a1dc-480f-abe4-436084af64ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","175/175 [==============================] - 15s 71ms/step - loss: 0.6022 - accuracy: 0.2526 - val_loss: 0.5631 - val_accuracy: 0.2921\n","Epoch 2/10\n","175/175 [==============================] - 13s 75ms/step - loss: 0.4717 - accuracy: 0.3265 - val_loss: 0.5042 - val_accuracy: 0.3029\n","Epoch 3/10\n","175/175 [==============================] - 13s 74ms/step - loss: 0.2667 - accuracy: 0.3501 - val_loss: 0.6130 - val_accuracy: 0.3007\n","Epoch 4/10\n","175/175 [==============================] - 13s 75ms/step - loss: 0.1446 - accuracy: 0.3553 - val_loss: 0.7999 - val_accuracy: 0.2986\n","Epoch 5/10\n","175/175 [==============================] - 13s 73ms/step - loss: 0.0978 - accuracy: 0.3787 - val_loss: 0.9591 - val_accuracy: 0.2993\n","Epoch 6/10\n","175/175 [==============================] - 12s 68ms/step - loss: 0.0786 - accuracy: 0.3807 - val_loss: 1.1025 - val_accuracy: 0.2979\n","Epoch 7/10\n","175/175 [==============================] - 12s 71ms/step - loss: 0.0668 - accuracy: 0.3821 - val_loss: 1.2483 - val_accuracy: 0.2943\n","Epoch 8/10\n","175/175 [==============================] - 13s 76ms/step - loss: 0.0617 - accuracy: 0.3901 - val_loss: 1.3887 - val_accuracy: 0.2993\n","Epoch 9/10\n","175/175 [==============================] - 13s 74ms/step - loss: 0.0589 - accuracy: 0.3869 - val_loss: 1.4343 - val_accuracy: 0.2986\n","Epoch 10/10\n","175/175 [==============================] - 12s 71ms/step - loss: 0.0575 - accuracy: 0.3789 - val_loss: 1.4582 - val_accuracy: 0.3064\n"]}]},{"cell_type":"markdown","source":["성능이 어느정도 증가하였으나 kmhas 데이터셋에서와 마찬가지로 multi classification 문제에서는 1d-cnn이 충분한 성능을 내지 못할 것 같다."],"metadata":{"id":"iI8sGG_5A0lG"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 읽기\n",
    "file_path = '/Users/simgyuseong/Documents/Hate_Detection/dataset/raw/kmhas_data/kmhas_raw.txt'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 새로운 라벨 열을 생성\n",
    "labels = [\"출신차별\", \"외모차별\", \"정치성향차별\", \"혐오욕설\", \"연령차별\", \"성차별\", \"인종차별\", \"종교차별\", \"해당사항 없음\"]\n",
    "label_map = {0: \"출신차별\", 1: \"외모차별\", 2: \"정치성향차별\", 3: \"혐오욕설\", 4: \"연령차별\", 5: \"성차별\", 6: \"인종차별\", 7: \"종교차별\", 8: \"해당사항 없음\"}\n",
    "\n",
    "# 기존 라벨들을 0과 1로 변환\n",
    "for label in labels:\n",
    "    df[label] = 0\n",
    "\n",
    "# 기존 라벨을 ,로 분리하여 새로운 라벨 값 설정\n",
    "for index, row in df.iterrows():\n",
    "    if not pd.isna(row['label']):\n",
    "        for label in map(int, row['label'].split(',')):\n",
    "            label_name = label_map[label]\n",
    "            df.at[index, label_name] = 1\n",
    "\n",
    "# 불필요한 기존 라벨 열 제거\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# 파일 저장\n",
    "output_path = '/Users/simgyuseong/Documents/Hate_Detection/dataset/raw/kmhas_data/kmhas_dataset.csv'\n",
    "df.to_csv(output_path, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/simgyuseong/Documents/Hate_Detection/dataset/raw/kmhas_data/kmhas_dataset.txt',delimiter = '\\t',on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>출신차별</th>\n",
       "      <th>외모차별</th>\n",
       "      <th>정치성향차별</th>\n",
       "      <th>혐오욕설</th>\n",
       "      <th>연령차별</th>\n",
       "      <th>성차별</th>\n",
       "      <th>인종차별</th>\n",
       "      <th>종교차별</th>\n",
       "      <th>해당사항 없음</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자한당틀딱들.. 악플질 고만해라.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>정치적으로 편향된 평론한은 분은 별로...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>적당히좀 쳐먹지.그랬냐??? 안그래도 문재인 때문에 나라 엉망진창인데...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>안서는 아재들 풀발기 ㅋㄲㅋ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>우와 ㅋ 능력자</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>맛녀석 콩트보다 약했음맛녀석 애청자로써 70%실력발휘</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>주영훈 솔직히 호감임 잉꼬부부로 소문났잖아</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>이게주간아이돌이랑머가달라...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>아오 슈박 회사생활도 졑깥고 돈벌기 힘들어 죽겠구만 뭔 저딴것들 자꾸 tv나와서 사...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>문재인 하는게 뭐 별거있냐?ㅂㅅㅅㅋ가 하는짓인데 어련하겠어.ㅋㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  출신차별  외모차별  정치성향차별  \\\n",
       "0                                 자한당틀딱들.. 악플질 고만해라.     0     0       1   \n",
       "1                            정치적으로 편향된 평론한은 분은 별로...     0     0       0   \n",
       "2          적당히좀 쳐먹지.그랬냐??? 안그래도 문재인 때문에 나라 엉망진창인데...     0     0       1   \n",
       "3                                    안서는 아재들 풀발기 ㅋㄲㅋ     0     0       0   \n",
       "4                                           우와 ㅋ 능력자     0     0       0   \n",
       "5                      맛녀석 콩트보다 약했음맛녀석 애청자로써 70%실력발휘     0     0       0   \n",
       "6                            주영훈 솔직히 호감임 잉꼬부부로 소문났잖아     0     0       0   \n",
       "7                                   이게주간아이돌이랑머가달라...     0     0       0   \n",
       "8  아오 슈박 회사생활도 졑깥고 돈벌기 힘들어 죽겠구만 뭔 저딴것들 자꾸 tv나와서 사...     0     0       0   \n",
       "9               문재인 하는게 뭐 별거있냐?ㅂㅅㅅㅋ가 하는짓인데 어련하겠어.ㅋㅋㅋ     0     0       1   \n",
       "\n",
       "   혐오욕설  연령차별  성차별  인종차별  종교차별  해당사항 없음  \n",
       "0     0     1    0     0     0        0  \n",
       "1     0     0    0     0     0        1  \n",
       "2     0     0    0     0     0        0  \n",
       "3     0     1    0     0     0        0  \n",
       "4     0     0    0     0     0        1  \n",
       "5     0     0    0     0     0        1  \n",
       "6     0     0    0     0     0        1  \n",
       "7     0     0    0     0     0        1  \n",
       "8     1     0    0     0     0        0  \n",
       "9     1     0    0     0     0        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    document  출신차별  외모차별  정치성향차별  혐오욕설  연령차별  \\\n",
      "0                         자한당틀딱들.. 악플질 고만해라.     0     0       1     0     1   \n",
      "1                    정치적으로 편향된 평론한은 분은 별로...     0     0       0     0     0   \n",
      "2  적당히좀 쳐먹지.그랬냐??? 안그래도 문재인 때문에 나라 엉망진창인데...     0     0       1     0     0   \n",
      "3                            안서는 아재들 풀발기 ㅋㄲㅋ     0     0       0     0     1   \n",
      "4                                   우와 ㅋ 능력자     0     0       0     0     0   \n",
      "\n",
      "   성차별  인종차별  종교차별  해당사항 없음  \n",
      "0    0     0     0        0  \n",
      "1    0     0     0        1  \n",
      "2    0     0     0        0  \n",
      "3    0     0     0        0  \n",
      "4    0     0     0        1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/pq30895j7xl996rt4n_pcm0r0000gn/T/ipykernel_79044/329801876.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return [labels[i] for i in range(len(labels)) if row[i+1] == 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (109692, 100)\n",
      "Shape of y: (109692, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/simgyuseong/Documents/Hate_Detection/dataset/raw/kmhas_data/kmhas_dataset.txt'\n",
    "data = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Define the labels\n",
    "labels = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '해당사항 없음']\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    # Remove non-alphanumeric characters and extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-Z가-힣0-9\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "# Clean the 'document' column\n",
    "data['document'] = data['document'].apply(clean_text)\n",
    "\n",
    "# Convert labels to a list of labels\n",
    "def extract_labels(row):\n",
    "    return [labels[i] for i in range(len(labels)) if row[i+1] == 1]\n",
    "\n",
    "data['labels'] = data.apply(extract_labels, axis=1)\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['document'])\n",
    "sequences = tokenizer.texts_to_sequences(data['document'])\n",
    "\n",
    "# Pad the sequences\n",
    "maxlen = 100  # You can adjust the maxlen according to your needs\n",
    "X = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# Binarize the labels\n",
    "mlb = MultiLabelBinarizer(classes=labels)\n",
    "y = mlb.fit_transform(data['labels'])\n",
    "\n",
    "# Print the shape of the dataset\n",
    "print(f'Shape of X: {X.shape}')\n",
    "print(f'Shape of y: {y.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 283379\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 248418\n",
      "단어 집합에서 희귀 단어의 비율: 87.66281199383158\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 36.01167770884504\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 34963\n"
     ]
    }
   ],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Wh2kKdzsfDD","executionInfo":{"status":"ok","timestamp":1716256531613,"user_tz":-540,"elapsed":16657,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"b1626181-0606-4718-a9f4-761d4550454c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Crum_LZGsFVA","executionInfo":{"status":"ok","timestamp":1716256541381,"user_tz":-540,"elapsed":3186,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"22570730-874c-45e6-f61f-b817aab1a121"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  문장  여성/가족  남성  성소수자  인종/국적  \\\n","0  ㅇㄱㄹㅇ 진짜 죽어도 상관없다는 마인드로 싸웠더니 지금 서열 상타취노 식칼들고 니가...      0   1     0      0   \n","1                         여자들은 취미가 애낳는건가.. 취미를 좀 가져라      1   0     0      0   \n","2                           개슬람녀 다 필요없고 니 엄마만 있으면 된다      0   0     0      1   \n","3  조팔ㅋㅋ 남한 길거리 돌아다니면 한국남자때문에 눈재기하는데 그걸 내 폰에 굳이 담아...      0   1     0      0   \n","4                              바지 내리다 한남들 와꾸 보고 올려뿟노      0   1     0      0   \n","\n","   연령  지역  종교  기타 혐오  악플/욕설  clean  개인지칭  \n","0   0   0   0      0      0      0     0  \n","1   0   0   0      0      0      0     0  \n","2   0   0   1      0      0      0     0  \n","3   0   0   0      0      0      0     0  \n","4   0   0   0      0      0      0     0  \n","Shape of X: (18742, 100)\n","Shape of y: (18742, 11)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import re\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Load the dataset\n","file_path = '/content/drive/MyDrive/DLproject/dataset/unsmile_dataset.txt'\n","data = pd.read_csv(file_path, delimiter='\\t')\n","\n","# Display the first few rows of the dataset\n","print(data.head())\n","\n","# Define the labels\n","labels = ['여성/가족', '남성', '성소수자', '인종/국적', '연령', '지역', '종교', '기타 혐오', '악플/욕설', 'clean', '개인지칭']\n","\n","# Text cleaning function\n","def clean_text(text):\n","    # Remove non-alphanumeric characters and extra spaces\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = re.sub(r\"[^a-zA-Z가-힣0-9\\s]\", \"\", text)\n","    return text.strip()\n","\n","# Clean the '문장' column\n","data['문장'] = data['문장'].apply(clean_text)\n","\n","# Convert labels to a list of labels\n","def extract_labels(row):\n","    return [labels[i] for i in range(len(labels)) if row[i+1] == 1]\n","\n","data['labels'] = data.apply(extract_labels, axis=1)\n","\n","# Tokenize the sentences\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(data['문장'])\n","sequences = tokenizer.texts_to_sequences(data['문장'])\n","\n","# Pad the sequences\n","maxlen = 100  # You can adjust the maxlen according to your needs\n","X = pad_sequences(sequences, maxlen=maxlen)\n","\n","# Binarize the labels\n","mlb = MultiLabelBinarizer(classes=labels)\n","y = mlb.fit_transform(data['labels'])\n","\n","# Print the shape of the dataset\n","print(f'Shape of X: {X.shape}')\n","print(f'Shape of y: {y.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83Ev99ddsFVF","executionInfo":{"status":"ok","timestamp":1716214733934,"user_tz":-540,"elapsed":2,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"77a64e45-a497-4ed6-b0fe-dde8f9509ef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합(vocabulary)의 크기 : 79471\n","등장 빈도가 2번 이하인 희귀 단어의 수: 71542\n","단어 집합에서 희귀 단어의 비율: 90.02277560367932\n","전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 49.58030465836546\n"]}],"source":["threshold = 3\n","total_cnt = len(tokenizer.word_index) # 단어의 수\n","rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n","rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n","\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n","for key, value in tokenizer.word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('단어 집합(vocabulary)의 크기 :',total_cnt)\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NK5O3JmesFVG","executionInfo":{"status":"ok","timestamp":1716214736288,"user_tz":-540,"elapsed":374,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"5a92740d-058a-42d3-8e4c-0f13927737ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합의 크기 : 7931\n"]}],"source":["# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n","# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n","vocab_size = total_cnt - rare_cnt + 2\n","print('단어 집합의 크기 :',vocab_size)"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n","embedding_dim = 128\n","\n","\n","model_01 = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n","    Conv1D(filters=128, kernel_size=5, activation='relu'),\n","    MaxPooling1D(pool_size=2),\n","    Conv1D(filters=128, kernel_size=5, activation='relu'),\n","    GlobalMaxPooling1D(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(y.shape[1], activation='sigmoid')  # Use 'sigmoid' for multi-label classification\n","])\n","\n","model_01.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model_01.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlZdCzhSXWl2","executionInfo":{"status":"ok","timestamp":1716216265866,"user_tz":-540,"elapsed":1342,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"74c09c52-cb27-44c5-84c6-9bbf6046e08e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 100, 128)          10172416  \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 96, 128)           82048     \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 48, 128)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 44, 128)           82048     \n","                                                                 \n"," global_max_pooling1d_1 (Gl  (None, 128)               0         \n"," obalMaxPooling1D)                                               \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 11)                1419      \n","                                                                 \n","=================================================================\n","Total params: 10354443 (39.50 MB)\n","Trainable params: 10354443 (39.50 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","\n","from tensorflow.keras.callbacks import Callback\n","import numpy as np\n","\n","#초반엔 오버피팅이 일어나서 얼리스탑 룰을 적용해본다...\n","\n","class EarlyStoppingByAccuracyDiff(Callback):\n","    def __init__(self, monitor='accuracy', value=0.4, verbose=0):\n","        super(Callback, self).__init__()\n","        self.monitor = monitor\n","        self.value = value\n","        self.verbose = verbose\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        train_acc = logs.get('accuracy')\n","        val_acc = logs.get('val_accuracy')\n","\n","        if train_acc and val_acc:\n","            acc_diff = np.abs(train_acc - val_acc)\n","            if acc_diff >= self.value:\n","                if self.verbose > 0:\n","                    print(f\"\\nEpoch {epoch + 1}: early stopping triggered as accuracy difference {acc_diff:.4f} is greater than {self.value}\")\n","                self.model.stop_training = True\n","\n","# Create an instance of the custom callback\n","early_stopping_by_acc_diff = EarlyStoppingByAccuracyDiff(monitor='accuracy', value=0.4, verbose=1)\n","\n","# Use the callback in model training\n","history = model_01.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=1, callbacks=[early_stopping_by_acc_diff])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGqGPpDuXtv2","executionInfo":{"status":"ok","timestamp":1716216877381,"user_tz":-540,"elapsed":397329,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"32abb713-53e6-4905-afd5-ee5b64a6d320"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","375/375 [==============================] - 91s 240ms/step - loss: 0.3257 - accuracy: 0.2277 - val_loss: 0.2890 - val_accuracy: 0.2801\n","Epoch 2/10\n","375/375 [==============================] - 87s 233ms/step - loss: 0.2709 - accuracy: 0.3514 - val_loss: 0.2829 - val_accuracy: 0.3464\n","Epoch 3/10\n","375/375 [==============================] - 87s 231ms/step - loss: 0.2032 - accuracy: 0.5680 - val_loss: 0.2874 - val_accuracy: 0.3648\n","Epoch 4/10\n","375/375 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.7608\n","Epoch 4: early stopping triggered as accuracy difference 0.4020 is greater than 0.4\n","375/375 [==============================] - 89s 237ms/step - loss: 0.1286 - accuracy: 0.7608 - val_loss: 0.3314 - val_accuracy: 0.3588\n"]}]},{"cell_type":"markdown","source":["1. 필터 크기 다양화\n","2. CNN레이어 여러개 쌓음\n","3. 배치 정규화 추가\n","4. Golbal Average Pooling 사용"],"metadata":{"id":"KlxLl1cF2s_7"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, GlobalAveragePooling1D, Dense, Dropout, BatchNormalization\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 모델 정의\n","model_02 = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n","    Conv1D(filters=128, kernel_size=3, activation='relu'),\n","    BatchNormalization(),\n","    Conv1D(filters=128, kernel_size=5, activation='relu'),\n","    BatchNormalization(),\n","    Conv1D(filters=128, kernel_size=7, activation='relu'),\n","    BatchNormalization(),\n","    GlobalAveragePooling1D(),  # Global Average Pooling 사용\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(y.shape[1], activation='sigmoid')\n","])\n","\n","model_02.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model_02.summary()\n","\n","# 모델 학습\n","history = model_02.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=32)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfEwbFSS5t2P","executionInfo":{"status":"ok","timestamp":1716257450193,"user_tz":-540,"elapsed":72476,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"558c6544-17af-4a34-a242-e5cb61fdbe82"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_5 (Embedding)     (None, 100, 128)          10172416  \n","                                                                 \n"," conv1d_14 (Conv1D)          (None, 98, 128)           49280     \n","                                                                 \n"," batch_normalization_11 (Ba  (None, 98, 128)           512       \n"," tchNormalization)                                               \n","                                                                 \n"," conv1d_15 (Conv1D)          (None, 94, 128)           82048     \n","                                                                 \n"," batch_normalization_12 (Ba  (None, 94, 128)           512       \n"," tchNormalization)                                               \n","                                                                 \n"," conv1d_16 (Conv1D)          (None, 88, 128)           114816    \n","                                                                 \n"," batch_normalization_13 (Ba  (None, 88, 128)           512       \n"," tchNormalization)                                               \n","                                                                 \n"," global_average_pooling1d_4  (None, 128)               0         \n","  (GlobalAveragePooling1D)                                       \n","                                                                 \n"," dense_11 (Dense)            (None, 128)               16512     \n","                                                                 \n"," dropout_6 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_12 (Dense)            (None, 11)                1419      \n","                                                                 \n","=================================================================\n","Total params: 10438027 (39.82 MB)\n","Trainable params: 10437259 (39.81 MB)\n","Non-trainable params: 768 (3.00 KB)\n","_________________________________________________________________\n","Epoch 1/10\n","375/375 [==============================] - 23s 50ms/step - loss: 0.3286 - accuracy: 0.2340 - val_loss: 0.7201 - val_accuracy: 0.2181\n","Epoch 2/10\n","375/375 [==============================] - 7s 18ms/step - loss: 0.2467 - accuracy: 0.4477 - val_loss: 0.3837 - val_accuracy: 0.1591\n","Epoch 3/10\n","375/375 [==============================] - 6s 15ms/step - loss: 0.1318 - accuracy: 0.7640 - val_loss: 0.6101 - val_accuracy: 0.2784\n","Epoch 4/10\n","375/375 [==============================] - 4s 12ms/step - loss: 0.0730 - accuracy: 0.8865 - val_loss: 1.3316 - val_accuracy: 0.2104\n","Epoch 5/10\n","375/375 [==============================] - 6s 15ms/step - loss: 0.0489 - accuracy: 0.9260 - val_loss: 0.7520 - val_accuracy: 0.2904\n","Epoch 6/10\n","375/375 [==============================] - 4s 11ms/step - loss: 0.0360 - accuracy: 0.9452 - val_loss: 0.6191 - val_accuracy: 0.3668\n","Epoch 7/10\n","375/375 [==============================] - 4s 11ms/step - loss: 0.0298 - accuracy: 0.9491 - val_loss: 0.7413 - val_accuracy: 0.2804\n","Epoch 8/10\n","375/375 [==============================] - 7s 19ms/step - loss: 0.0249 - accuracy: 0.9504 - val_loss: 0.7912 - val_accuracy: 0.3765\n","Epoch 9/10\n","375/375 [==============================] - 5s 13ms/step - loss: 0.0212 - accuracy: 0.9528 - val_loss: 0.7477 - val_accuracy: 0.3675\n","Epoch 10/10\n","375/375 [==============================] - 6s 15ms/step - loss: 0.0194 - accuracy: 0.9506 - val_loss: 1.2251 - val_accuracy: 0.1314\n"]}]},{"cell_type":"markdown","source":["1. 필터 크기 다양화\n","2. CNN레이어 여러개 쌓음\n","3. 배치 정규화 추가\n","4. Attention Mechanism 사용"],"metadata":{"id":"ZG5v2dae6rGr"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n","from tensorflow.keras import backend as K\n","from sklearn.model_selection import train_test_split\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Attention Mechanism 구현\n","class Attention(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super(Attention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1), initializer='random_normal', trainable=True)\n","        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1), initializer='zeros', trainable=True)\n","        super(Attention, self).build(input_shape)\n","\n","    def call(self, x):\n","        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n","        e = tf.keras.backend.squeeze(e, axis=-1)\n","        alpha = tf.keras.backend.softmax(e)\n","        alpha = tf.keras.backend.expand_dims(alpha, axis=-1)\n","        context = x * alpha\n","        context = tf.keras.backend.sum(context, axis=1)\n","        return context\n","\n","# 모델 정의\n","model_03 = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n","    Conv1D(filters=128, kernel_size=3, activation='relu'),\n","    BatchNormalization(),\n","    Conv1D(filters=128, kernel_size=5, activation='relu'),\n","    BatchNormalization(),\n","    Conv1D(filters=128, kernel_size=7, activation='relu'),\n","    BatchNormalization(),\n","    Attention(),  # Attention Mechanism 추가\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(y.shape[1], activation='sigmoid')\n","])\n","\n","model_03.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model_03.summary()\n","\n","# 모델 학습\n","history = model_03.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=32)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IFXE-wZ6v2q","executionInfo":{"status":"ok","timestamp":1716257714255,"user_tz":-540,"elapsed":85023,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"30f059f6-48b5-4ded-d40c-d8fc45fdbe5c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_8 (Embedding)     (None, 100, 128)          10172416  \n","                                                                 \n"," conv1d_22 (Conv1D)          (None, 98, 128)           49280     \n","                                                                 \n"," batch_normalization_19 (Ba  (None, 98, 128)           512       \n"," tchNormalization)                                               \n","                                                                 \n"," conv1d_23 (Conv1D)          (None, 94, 128)           82048     \n","                                                                 \n"," batch_normalization_20 (Ba  (None, 94, 128)           512       \n"," tchNormalization)                                               \n","                                                                 \n"," conv1d_24 (Conv1D)          (None, 88, 128)           114816    \n","                                                                 \n"," batch_normalization_21 (Ba  (None, 88, 128)           512       \n"," tchNormalization)                                               \n","                                                                 \n"," attention (Attention)       (None, 128)               216       \n","                                                                 \n"," dense_17 (Dense)            (None, 128)               16512     \n","                                                                 \n"," dropout_9 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_18 (Dense)            (None, 11)                1419      \n","                                                                 \n","=================================================================\n","Total params: 10438243 (39.82 MB)\n","Trainable params: 10437475 (39.82 MB)\n","Non-trainable params: 768 (3.00 KB)\n","_________________________________________________________________\n","Epoch 1/10\n","375/375 [==============================] - 24s 53ms/step - loss: 0.3250 - accuracy: 0.2199 - val_loss: 0.6948 - val_accuracy: 0.0867\n","Epoch 2/10\n","375/375 [==============================] - 6s 16ms/step - loss: 0.2836 - accuracy: 0.2859 - val_loss: 0.5576 - val_accuracy: 0.2321\n","Epoch 3/10\n","375/375 [==============================] - 7s 18ms/step - loss: 0.2311 - accuracy: 0.4361 - val_loss: 7.6946 - val_accuracy: 0.0650\n","Epoch 4/10\n","375/375 [==============================] - 4s 12ms/step - loss: 0.1510 - accuracy: 0.7079 - val_loss: 0.4925 - val_accuracy: 0.1854\n","Epoch 5/10\n","375/375 [==============================] - 4s 12ms/step - loss: 0.0871 - accuracy: 0.8533 - val_loss: 2.3632 - val_accuracy: 0.2084\n","Epoch 6/10\n","375/375 [==============================] - 6s 15ms/step - loss: 0.0566 - accuracy: 0.9147 - val_loss: 0.7317 - val_accuracy: 0.2588\n","Epoch 7/10\n","375/375 [==============================] - 4s 12ms/step - loss: 0.0420 - accuracy: 0.9351 - val_loss: 3.1279 - val_accuracy: 0.2628\n","Epoch 8/10\n","375/375 [==============================] - 4s 12ms/step - loss: 0.0337 - accuracy: 0.9466 - val_loss: 0.9139 - val_accuracy: 0.2681\n","Epoch 9/10\n","375/375 [==============================] - 5s 13ms/step - loss: 0.0261 - accuracy: 0.9535 - val_loss: 1.2220 - val_accuracy: 0.3118\n","Epoch 10/10\n","375/375 [==============================] - 4s 11ms/step - loss: 0.0216 - accuracy: 0.9582 - val_loss: 0.5506 - val_accuracy: 0.2431\n"]}]},{"cell_type":"markdown","source":["오버피팅 문제가 해결되지 않으므로\n","모델을 단순화하고 k-fold 방식을 실행해 본다\n"],"metadata":{"id":"LNw8xTPZ-6z6"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n","\n","# K-fold 설정\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# 결과 저장용 리스트\n","val_accuracies = []\n","val_losses = []\n","\n","for train_index, val_index in kf.split(X):\n","    X_train, X_val = X[train_index], X[val_index]\n","    y_train, y_val = y[train_index], y[val_index]\n","\n","    # 모델 정의\n","    model = Sequential([\n","        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n","        Conv1D(filters=64, kernel_size=3, activation='relu'),\n","        BatchNormalization(),\n","        Dropout(0.5),\n","        Conv1D(filters=64, kernel_size=5, activation='relu'),\n","        BatchNormalization(),\n","        Dropout(0.5),\n","        GlobalMaxPooling1D(),\n","        Dense(64, activation='relu'),\n","        Dropout(0.5),\n","        Dense(y.shape[1], activation='sigmoid')\n","    ])\n","\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","\n","\n","    # 모델 학습\n","    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), batch_size=32)\n","\n","    # 모델 평가\n","    val_loss, val_accuracy = model.evaluate(X_val, y_val)\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","\n","    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n","\n","# 최종 평균 성능 출력\n","print(f'Mean Validation Loss: {np.mean(val_losses)}, Mean Validation Accuracy: {np.mean(val_accuracies)}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"w3OczRuf_D-a","executionInfo":{"status":"ok","timestamp":1716259155746,"user_tz":-540,"elapsed":331142,"user":{"displayName":"김경민, 산업정보시스템전공(학부)","userId":"00050835421470418756"}},"outputId":"3391ba6f-872e-42d3-c164-8a4dcaa773de"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 23s 42ms/step - loss: 0.5034 - accuracy: 0.1875 - val_loss: 0.5905 - val_accuracy: 0.1136\n","Epoch 2/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.3303 - accuracy: 0.2398 - val_loss: 0.4074 - val_accuracy: 0.2505\n","Epoch 3/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.3175 - accuracy: 0.2499 - val_loss: 0.4355 - val_accuracy: 0.2505\n","Epoch 4/20\n","469/469 [==============================] - 6s 13ms/step - loss: 0.3096 - accuracy: 0.2490 - val_loss: 0.4825 - val_accuracy: 0.0165\n","Epoch 5/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2889 - accuracy: 0.2823 - val_loss: 0.3253 - val_accuracy: 0.2518\n","Epoch 6/20\n","469/469 [==============================] - 5s 10ms/step - loss: 0.2666 - accuracy: 0.3356 - val_loss: 0.2998 - val_accuracy: 0.2641\n","Epoch 7/20\n","469/469 [==============================] - 6s 12ms/step - loss: 0.2408 - accuracy: 0.4029 - val_loss: 0.3247 - val_accuracy: 0.2198\n","Epoch 8/20\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2154 - accuracy: 0.4743 - val_loss: 0.3030 - val_accuracy: 0.2585\n","Epoch 9/20\n","469/469 [==============================] - 5s 10ms/step - loss: 0.1916 - accuracy: 0.5258 - val_loss: 0.3127 - val_accuracy: 0.2334\n","118/118 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.2641\n","Validation Loss: 0.2997813820838928, Validation Accuracy: 0.26407042145729065\n","Epoch 1/20\n","469/469 [==============================] - 22s 40ms/step - loss: 0.5290 - accuracy: 0.1824 - val_loss: 0.5821 - val_accuracy: 0.2033\n","Epoch 2/20\n","469/469 [==============================] - 7s 14ms/step - loss: 0.3308 - accuracy: 0.2312 - val_loss: 0.4258 - val_accuracy: 0.2353\n","Epoch 3/20\n","469/469 [==============================] - 6s 13ms/step - loss: 0.3176 - accuracy: 0.2466 - val_loss: 0.4596 - val_accuracy: 0.2251\n","Epoch 4/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.3087 - accuracy: 0.2607 - val_loss: 0.4760 - val_accuracy: 0.2115\n","Epoch 5/20\n","469/469 [==============================] - 6s 13ms/step - loss: 0.2917 - accuracy: 0.3001 - val_loss: 0.4071 - val_accuracy: 0.2094\n","Epoch 6/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2663 - accuracy: 0.3690 - val_loss: 0.3068 - val_accuracy: 0.2761\n","Epoch 7/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2348 - accuracy: 0.4527 - val_loss: 0.3178 - val_accuracy: 0.2641\n","Epoch 8/20\n","469/469 [==============================] - 6s 12ms/step - loss: 0.1997 - accuracy: 0.5476 - val_loss: 0.3191 - val_accuracy: 0.2790\n","Epoch 9/20\n","469/469 [==============================] - 5s 10ms/step - loss: 0.1731 - accuracy: 0.6092 - val_loss: 0.3076 - val_accuracy: 0.3220\n","118/118 [==============================] - 0s 3ms/step - loss: 0.3068 - accuracy: 0.2761\n","Validation Loss: 0.3067648410797119, Validation Accuracy: 0.2760736048221588\n","Epoch 1/20\n","469/469 [==============================] - 23s 45ms/step - loss: 0.5237 - accuracy: 0.1701 - val_loss: 0.5387 - val_accuracy: 0.1550\n","Epoch 2/20\n","469/469 [==============================] - 6s 13ms/step - loss: 0.3304 - accuracy: 0.2348 - val_loss: 0.4423 - val_accuracy: 0.2460\n","Epoch 3/20\n","469/469 [==============================] - 6s 13ms/step - loss: 0.3173 - accuracy: 0.2488 - val_loss: 0.4301 - val_accuracy: 0.2497\n","Epoch 4/20\n","469/469 [==============================] - 5s 10ms/step - loss: 0.3102 - accuracy: 0.2526 - val_loss: 0.4588 - val_accuracy: 0.1457\n","Epoch 5/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2934 - accuracy: 0.2774 - val_loss: 0.3744 - val_accuracy: 0.2465\n","Epoch 6/20\n","469/469 [==============================] - 5s 12ms/step - loss: 0.2663 - accuracy: 0.3389 - val_loss: 0.3396 - val_accuracy: 0.2287\n","Epoch 7/20\n","469/469 [==============================] - 5s 10ms/step - loss: 0.2345 - accuracy: 0.4230 - val_loss: 0.3271 - val_accuracy: 0.2452\n","Epoch 8/20\n","469/469 [==============================] - 5s 12ms/step - loss: 0.2014 - accuracy: 0.5093 - val_loss: 0.3152 - val_accuracy: 0.2575\n","Epoch 9/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1772 - accuracy: 0.5644 - val_loss: 0.3144 - val_accuracy: 0.2745\n","Epoch 10/20\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1589 - accuracy: 0.6094 - val_loss: 0.3249 - val_accuracy: 0.2377\n","Epoch 11/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1490 - accuracy: 0.6370 - val_loss: 0.3239 - val_accuracy: 0.3151\n","118/118 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.2575\n","Validation Loss: 0.31523165106773376, Validation Accuracy: 0.25747063755989075\n","Epoch 1/20\n","469/469 [==============================] - 22s 43ms/step - loss: 0.5326 - accuracy: 0.1693 - val_loss: 0.4775 - val_accuracy: 0.2572\n","Epoch 2/20\n","469/469 [==============================] - 6s 13ms/step - loss: 0.3319 - accuracy: 0.2352 - val_loss: 0.3757 - val_accuracy: 0.2647\n","Epoch 3/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.3172 - accuracy: 0.2480 - val_loss: 0.3953 - val_accuracy: 0.2607\n","Epoch 4/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.3048 - accuracy: 0.2603 - val_loss: 0.4101 - val_accuracy: 0.1705\n","Epoch 5/20\n","469/469 [==============================] - 6s 12ms/step - loss: 0.2809 - accuracy: 0.3100 - val_loss: 0.3847 - val_accuracy: 0.1892\n","118/118 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.2647\n","Validation Loss: 0.3757050931453705, Validation Accuracy: 0.26467448472976685\n","Epoch 1/20\n","469/469 [==============================] - 23s 43ms/step - loss: 0.5233 - accuracy: 0.1755 - val_loss: 0.5050 - val_accuracy: 0.2097\n","Epoch 2/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.3330 - accuracy: 0.2405 - val_loss: 0.3958 - val_accuracy: 0.2340\n","Epoch 3/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.3163 - accuracy: 0.2523 - val_loss: 0.4226 - val_accuracy: 0.2065\n","Epoch 4/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.3025 - accuracy: 0.2700 - val_loss: 0.4116 - val_accuracy: 0.2284\n","Epoch 5/20\n","469/469 [==============================] - 6s 12ms/step - loss: 0.2784 - accuracy: 0.3263 - val_loss: 0.3501 - val_accuracy: 0.2588\n","Epoch 6/20\n","469/469 [==============================] - 5s 10ms/step - loss: 0.2532 - accuracy: 0.3850 - val_loss: 0.3031 - val_accuracy: 0.2751\n","Epoch 7/20\n","469/469 [==============================] - 5s 12ms/step - loss: 0.2234 - accuracy: 0.4593 - val_loss: 0.3044 - val_accuracy: 0.2505\n","Epoch 8/20\n","469/469 [==============================] - 5s 11ms/step - loss: 0.1985 - accuracy: 0.5159 - val_loss: 0.3536 - val_accuracy: 0.1846\n","Epoch 9/20\n","469/469 [==============================] - 4s 9ms/step - loss: 0.1827 - accuracy: 0.5518 - val_loss: 0.3196 - val_accuracy: 0.2769\n","118/118 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.2751\n","Validation Loss: 0.3030795753002167, Validation Accuracy: 0.2750800549983978\n","Mean Validation Loss: 0.32011250853538514, Mean Validation Accuracy: 0.267473840713501\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}